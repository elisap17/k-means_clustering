{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "brave-trial",
   "metadata": {},
   "source": [
    "# Spark k-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ignored-entity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des bibliotheques\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "import os, shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooked-technology",
   "metadata": {},
   "source": [
    "**Q1) Instanciation du client Spark Session**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "restricted-macintosh",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder\\\n",
    "                    .master(\"local\")\\\n",
    "                    .appName(\"kmeans_clustering\")\\\n",
    "                    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "variable-deployment",
   "metadata": {},
   "source": [
    "**Q2) Utilisation du fichier de configuration pour recuperer les path**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "central-principal",
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read('properties.conf')\n",
    "path_to_input_data = config['Bristol_city_bike']['input_data']\n",
    "path_to_output_data = config['Bristol_city_bike']['output_data']\n",
    "num_partition_kmeans = config['Bristol_city_bike']['kmeans_level']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specified-philosophy",
   "metadata": {},
   "source": [
    "**Q3) Importation du fichier Bristol-city-bike.json**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "elect-measurement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+----------+--------------------+------+\n",
      "|             address|  latitude| longitude|                name|number|\n",
      "+--------------------+----------+----------+--------------------+------+\n",
      "|Lower River Tce /...|-27.482279|153.028723|122 - LOWER RIVER...|   122|\n",
      "|Main St / Darragh St| -27.47059|153.036046|91 - MAIN ST / DA...|    91|\n",
      "|Sydney St Ferry T...|-27.474531|153.042728|88 - SYDNEY ST FE...|    88|\n",
      "|Browne St / James St|-27.461881|153.046986|75 - BROWNE ST / ...|    75|\n",
      "|Kurilpa Point / M...|-27.469658|153.016696|98 - KURILPA POIN...|    98|\n",
      "+--------------------+----------+----------+--------------------+------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- address: string (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- number: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bristol = spark.read.json(path_to_input_data) \n",
    "               \n",
    "bristol.show(5)\n",
    "bristol.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conventional-psychology",
   "metadata": {},
   "source": [
    "**Q4) Creation d'un new dataframe contenant uniquement les variables latitude et longitude**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "realistic-vocabulary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|  latitude| longitude|\n",
      "+----------+----------+\n",
      "|-27.482279|153.028723|\n",
      "| -27.47059|153.036046|\n",
      "|-27.474531|153.042728|\n",
      "+----------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kmeans_df = bristol[\"latitude\",\"longitude\"]\n",
    "kmeans_df.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latest-arrow",
   "metadata": {},
   "source": [
    "**Q5) k-means**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "crucial-sister",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.clustering import KMeans\n",
    "\n",
    "features = ('longitude','latitude')\n",
    "kmeans = KMeans().setK(int(num_partition_kmeans)).setSeed(1)\n",
    "assembler = VectorAssembler(inputCols = features, outputCol = \"features\")\n",
    "dataset = assembler.transform(kmeans_df)\n",
    "model = kmeans.fit(dataset)\n",
    "fitted = model.transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "partial-proportion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------------------+----------+\n",
      "|  latitude| longitude|            features|prediction|\n",
      "+----------+----------+--------------------+----------+\n",
      "|-27.482279|153.028723|[153.028723,-27.4...|         2|\n",
      "| -27.47059|153.036046|[153.036046,-27.4...|         2|\n",
      "|-27.474531|153.042728|[153.042728,-27.4...|         1|\n",
      "|-27.461881|153.046986|[153.046986,-27.4...|         1|\n",
      "|-27.469658|153.016696|[153.016696,-27.4...|         2|\n",
      "| -27.48172| 153.00436|[153.00436,-27.48...|         0|\n",
      "|-27.493626|153.001482|[153.001482,-27.4...|         0|\n",
      "|-27.476076|153.002459|[153.002459,-27.4...|         0|\n",
      "|-27.493963|153.011938|[153.011938,-27.4...|         0|\n",
      "|-27.482197|153.020894|[153.020894,-27.4...|         2|\n",
      "|-27.465226|153.050864|[153.050864,-27.4...|         1|\n",
      "|-27.468447|153.024662|[153.024662,-27.4...|         2|\n",
      "|-27.473021|153.025988|[153.025988,-27.4...|         2|\n",
      "|-27.457825|153.036866|[153.036866,-27.4...|         1|\n",
      "| -27.48148| 153.02368|[153.02368,-27.48...|         2|\n",
      "|-27.467464|153.022094|[153.022094,-27.4...|         2|\n",
      "|-27.499963|153.017633|[153.017633,-27.4...|         0|\n",
      "|-27.490776|152.994747|[152.994747,-27.4...|         0|\n",
      "|-27.458199|153.041688|[153.041688,-27.4...|         1|\n",
      "|-27.481808|153.025477|[153.025477,-27.4...|         2|\n",
      "+----------+----------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fitted.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "other-yesterday",
   "metadata": {},
   "source": [
    "**Q6) Colonnes de fitted**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "level-rhythm",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['latitude', 'longitude', 'features', 'prediction']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "together-sending",
   "metadata": {},
   "source": [
    "**Q7) latitude et longitude moyenne de chaque groupe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "sharp-nomination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+------------------+\n",
      "|prediction|   Moyenne_latitude| Moyenne_longitude|\n",
      "+----------+-------------------+------------------+\n",
      "|         1|-27.460240636363633|153.04186302272726|\n",
      "|         2| -27.47255990624999|   153.02594553125|\n",
      "|         0|-27.481218536585374|153.00572882926832|\n",
      "+----------+-------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#DSL\n",
    "fitted.groupBy(\"prediction\") \\\n",
    "        .agg(avg(\"latitude\").alias(\"Moyenne_latitude\"), avg(\"longitude\").alias(\"Moyenne_longitude\")) \\\n",
    "        .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "foreign-australia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+------------------+\n",
      "|prediction|   Moyenne_latitude| Moyenne_longitude|\n",
      "+----------+-------------------+------------------+\n",
      "|         1|-27.460240636363633|153.04186302272726|\n",
      "|         2| -27.47255990624999|   153.02594553125|\n",
      "|         0|-27.481218536585374|153.00572882926832|\n",
      "+----------+-------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SQL\n",
    "fitted.createOrReplaceTempView(\"fitted_sql\") \n",
    "spark.sql(\"\"\" SELECT prediction, \n",
    "                     AVG(latitude) as Moyenne_latitude, \n",
    "                     AVG(longitude) as Moyenne_longitude \n",
    "              FROM fitted_sql \n",
    "              GROUP BY prediction \"\"\") \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powered-january",
   "metadata": {},
   "source": [
    "**Q8) Visualisation dans une map**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "burning-updating",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a7766e43d3745319095fd8eddc0cd8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[-27.460240636363633, 153.04186302272726], controls=(ZoomControl(options=['position', 'zoom_in_textâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipyleaflet import Map, Marker, AwesomeIcon\n",
    "\n",
    "center = (-27.460240636363633, 153.04186302272726)\n",
    "m = Map(center = center)\n",
    "\n",
    "icons = [\n",
    "    AwesomeIcon(\n",
    "        name='bicycle',\n",
    "        marker_color='lightblue',\n",
    "        icon_color='black',\n",
    "        spin=False\n",
    "    ), \n",
    "    AwesomeIcon(\n",
    "        name='bicycle',\n",
    "        marker_color='lightred',\n",
    "        icon_color='black',\n",
    "        spin=False\n",
    "    ), \n",
    "    AwesomeIcon(\n",
    "        name='bicycle',\n",
    "        marker_color='beige',\n",
    "        icon_color='black',\n",
    "        spin=False\n",
    "    )\n",
    "]\n",
    "\n",
    "for row in fitted.collect():\n",
    "    point = Marker(location = (row[\"latitude\"], row[\"longitude\"]), draggable = False, icon = icons[row[\"prediction\"]])\n",
    "    m.add_layer(point)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alert-given",
   "metadata": {},
   "source": [
    "**Q9) Exportation de fitted**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "pressed-output",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(path_to_output_data):\n",
    "    shutil.rmtree(path_to_output_data)\n",
    "    \n",
    "fitted = fitted.drop(\"features\")\n",
    "fitted.write.csv(path_to_output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "robust-jurisdiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
